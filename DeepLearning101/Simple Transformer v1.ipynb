{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6a0034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import re\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pickle\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ca63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼파라미터 설정\n",
    "PAD_token = 0  # 패딩 토큰\n",
    "SOS_token = 1  # 문장 시작 토큰\n",
    "EOS_token = 2  # 문장 끝 토큰\n",
    "UNK_token = 3  # 알 수 없는 토큰\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce5b1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰 생성 함수, 어휘 사전을 만들 때 사용됩니다.\n",
    "def yield_tokens(data_iter):\n",
    "    for text in data_iter:\n",
    "        yield tokenizer(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac4c7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 데이터 정리 함수\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):  # NaN 값을 처리합니다.\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', ' ', text)  # 모든 숫자를 공백으로 대체합니다.\n",
    "    text = re.sub(r'([^\\w\\s])', r' \\1 ', text)  # 각 구두점 문자 앞뒤에 공백을 추가합니다.\n",
    "    text = re.sub(r'\\s+', ' ', text)  # 연속된 공백을 하나의 공백으로 대체합니다.\n",
    "    text = text.strip()  # 앞뒤 공백을 제거합니다.\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d986611e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰을 텍스트로 변환하는 함수\n",
    "def tokens_to_text(tokens, VOCAB):\n",
    "    if isinstance(tokens, torch.Tensor):  # 토큰이 텐서인지 확인합니다.\n",
    "        tokens = tokens.cpu().numpy()\n",
    "    special_tokens = np.array([VOCAB['<SOS>'], VOCAB['<PAD>'], VOCAB['<UNK>'], VOCAB['<EOS>']])\n",
    "    tokens = [token for token in tokens if token not in special_tokens]\n",
    "    return ' '.join(VOCAB.lookup_tokens(tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a1b6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트를 토큰으로 변환하는 함수\n",
    "def text_to_tokens(text):\n",
    "    return [VOCAB[token] for token in tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1783ab31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch 데이터셋 클래스, 질문-답변 쌍을 다룹니다.\n",
    "class QADataset(Dataset):\n",
    "    def __init__(self, pairs, vocab, tokenizer, input_seq_len, target_seq_len):\n",
    "        self.pairs = pairs\n",
    "        self.vocab = vocab\n",
    "        self.tokenizer = tokenizer\n",
    "        self.input_seq_len = input_seq_len\n",
    "        self.target_seq_len = target_seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.pairs)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 질문과 답변을 쌍에서 가져옵니다.\n",
    "        question, answer = self.pairs[idx]\n",
    "\n",
    "        # 토큰화하고 인코딩합니다.\n",
    "        question_tokens = text_to_tokens(question)\n",
    "        answer_tokens = text_to_tokens(answer)\n",
    "\n",
    "        # 시퀀스를 패딩합니다.\n",
    "        enc_src = self.pad_sequence(question_tokens + [self.vocab['<EOS>']], self.input_seq_len)\n",
    "        dec_src = self.pad_sequence([self.vocab['<SOS>']] + answer_tokens, self.target_seq_len)\n",
    "        trg = self.pad_sequence([self.vocab['<SOS>']] + answer_tokens + [self.vocab['<EOS>']], \n",
    "                                self.target_seq_len)\n",
    "\n",
    "        return enc_src, dec_src, trg\n",
    "\n",
    "    def pad_sequence(self, seq, max_len):\n",
    "        return F.pad(torch.LongTensor(seq), (0, max_len - len(seq)), mode='constant', \n",
    "                     value=self.vocab['<PAD>'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d93b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 및 위치 임베딩 레이어\n",
    "class WordPositionEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size, max_seq_len, emb_size, device):\n",
    "        super(WordPositionEmbedding, self).__init__()\n",
    "        self.device = device\n",
    "        self.word_embedding = nn.Embedding(vocab_size, emb_size, device=device)\n",
    "\n",
    "        position = torch.arange(max_seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, emb_size, 2).float() * \n",
    "                             (-math.log(10000.0) / emb_size))\n",
    "        pos_emb = torch.zeros(max_seq_len, emb_size)\n",
    "        pos_emb[:, 0::2] = torch.sin(position * div_term)\n",
    "        pos_emb[:, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('position_embedding', pos_emb)\n",
    "\n",
    "    def forward(self, x):\n",
    "        word_embeddings = self.word_embedding(x)\n",
    "        pos_embeddings = self.position_embedding[:x.size(1), :]\n",
    "\n",
    "        # 단어 임베딩과 위치 임베딩을 결합합니다.\n",
    "        embeddings = word_embeddings + pos_embeddings\n",
    "        return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a073e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 멀티-헤드 어텐션 메커니즘 클래스\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, emb_size, heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.heads = heads\n",
    "        self.head_dim = emb_size // heads\n",
    "\n",
    "        assert self.head_dim * heads == emb_size, \"임베딩 크기는 헤드 수로 나누어 떨어져야 합니다.\"\n",
    "\n",
    "        self.values = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.keys = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.queries = nn.Linear(self.head_dim, self.head_dim, bias=False)\n",
    "        self.fc_out = nn.Linear(heads * self.head_dim, emb_size)\n",
    "\n",
    "    def forward(self, values, keys, queries, mask=None):\n",
    "        batch_size = queries.shape[0]\n",
    "        value_len, key_len, query_len = values.shape[1], keys.shape[1], queries.shape[1]\n",
    "\n",
    "        # 임베딩을 self.heads 개의 조각으로 나눕니다.\n",
    "        values = values.reshape(batch_size, self.heads, value_len, self.head_dim)\n",
    "        keys = keys.reshape(batch_size, self.heads, key_len, self.head_dim)\n",
    "        queries = queries.reshape(batch_size, self.heads, query_len, self.head_dim)\n",
    "\n",
    "        # 선형 변환을 수행합니다.\n",
    "        values = self.values(values)\n",
    "        keys = self.keys(keys)\n",
    "        queries = self.queries(queries)\n",
    "\n",
    "        # 행렬 곱셈을 위해 전치합니다.\n",
    "        keys_transposed = keys.transpose(2, 3)\n",
    "\n",
    "        # 각 헤드에 대해 쿼리와 키의 내적을 계산합니다.\n",
    "        energy = torch.matmul(queries, keys_transposed)\n",
    "\n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, float(\"-1e20\"))\n",
    "\n",
    "        # 에너지를 키의 차원의 제곱근으로 스케일링하고 소프트맥스를 적용합니다.\n",
    "        scale = self.head_dim ** 0.5\n",
    "        attention = torch.softmax(energy / scale, dim=-1)\n",
    "\n",
    "        # 어텐션 가중치를 값에 곱합니다.\n",
    "        out = torch.matmul(attention, values)\n",
    "\n",
    "        # 모든 헤드를 하나로 연결합니다.\n",
    "        out = out.reshape(batch_size, query_len, self.heads * self.head_dim)\n",
    "\n",
    "        # 최종 선형 레이어를 적용합니다.\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c727384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머 블록, 멀티-헤드 어텐션과 피드포워드 네트워크로 구성됩니다.\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, emb_size, heads, forward_expansion, dropout_rate):\n",
    "        super(TransformerBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(emb_size, heads)\n",
    "        self.norm1 = nn.LayerNorm(emb_size)\n",
    "        self.norm2 = nn.LayerNorm(emb_size)\n",
    "        self.feed_forward = nn.Sequential(\n",
    "            nn.Linear(emb_size, forward_expansion * emb_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(forward_expansion * emb_size, emb_size),\n",
    "        )\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, value, key, query, mask):\n",
    "        # 어텐션과 skip connection 연결\n",
    "        attention = self.attention(value, key, query, mask)\n",
    "        x = self.dropout(self.norm1(attention + query))\n",
    "\n",
    "        # 피드포워드와 skip connection 연결\n",
    "        forward = self.feed_forward(x)\n",
    "        out = self.norm2(self.dropout(forward + x))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cd2262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 트랜스포머 블록으로 구성된 인코더\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, emb_size, n_layers, heads, forward_expansion, \n",
    "                 drop_out, device):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.emb_size = emb_size\n",
    "        self.device = device\n",
    "        self.embedding = WordPositionEmbedding(vocab_size, seq_len, emb_size, device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            TransformerBlock(emb_size, heads, forward_expansion, drop_out) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, mask):\n",
    "        out = self.dropout(self.embedding(X))\n",
    "\n",
    "        # 각 트랜스포머 블록을 순차적으로 적용합니다.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, out, out, mask)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874c99da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 디코더 블록, 셀프 어텐션과 크로스 어텐션을 포함합니다.\n",
    "class DecoderBlock(nn.Module):\n",
    "    def __init__(self, emb_size, heads, forward_expansion, drop_out):\n",
    "        super(DecoderBlock, self).__init__()\n",
    "        self.attention = MultiHeadAttention(emb_size, heads)\n",
    "        self.norm = nn.LayerNorm(emb_size)\n",
    "        self.transformer_block = TransformerBlock(emb_size, heads, forward_expansion, drop_out)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, value, key, src_mask, trg_mask):\n",
    "        # 셀프 어텐션\n",
    "        attention = self.attention(X, X, X, trg_mask)\n",
    "        query = self.dropout(self.norm(attention + X))\n",
    "        # 인코더 출력과의 크로스 어텐션\n",
    "        out = self.transformer_block(value, key, query, src_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccd6420",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다중 디코더 블록으로 구성된 디코더\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, vocab_size, seq_len, emb_size, n_layers, heads, forward_expansion, \n",
    "                 drop_out, device):\n",
    "        super(Decoder, self).__init__()\n",
    "        self.device = device\n",
    "        self.embedding = WordPositionEmbedding(vocab_size, seq_len, emb_size, device)\n",
    "        self.layers = nn.ModuleList([\n",
    "            DecoderBlock(emb_size, heads, forward_expansion, drop_out) for _ in range(n_layers)\n",
    "        ])\n",
    "        self.fc_out = nn.Linear(emb_size, vocab_size)\n",
    "        self.dropout = nn.Dropout(drop_out)\n",
    "\n",
    "    def forward(self, X, enc_out, src_mask, trg_mask):\n",
    "        out = self.dropout(self.embedding(X))\n",
    "\n",
    "        # 각 디코더 블록을 처리합니다.\n",
    "        for layer in self.layers:\n",
    "            out = layer(out, enc_out, enc_out, src_mask, trg_mask)\n",
    "\n",
    "        # 어휘 사전으로 매핑하는 출력 레이어\n",
    "        out = self.fc_out(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f96c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 인코더와 디코더를 결합한 전체 트랜스포머 모델\n",
    "class TransformerScratch(nn.Module):\n",
    "    def __init__(self, inp_vocab_size, trg_vocab_size, src_pad_idx, trg_pad_idx, emb_size, \n",
    "                 n_layers=1, heads=1, forward_expansion=1, drop_out=0.2, max_seq_len=100, \n",
    "                 device=torch.device('cuda')):\n",
    "        super(TransformerScratch, self).__init__()\n",
    "\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "\n",
    "        self.encoder = Encoder(inp_vocab_size, max_seq_len, emb_size, n_layers, heads, \n",
    "                               forward_expansion, drop_out, device).to(device)\n",
    "        self.decoder = Decoder(trg_vocab_size, max_seq_len, emb_size, n_layers, heads, \n",
    "                               forward_expansion, drop_out, device).to(device)\n",
    "\n",
    "    def make_src_mask(self, src):\n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        return src_mask.to(self.device)\n",
    "\n",
    "    def make_trg_mask(self, trg):\n",
    "        batch_size, trg_seq_len = trg.shape\n",
    "        trg_mask = torch.tril(torch.ones((trg_seq_len, trg_seq_len))).expand(\n",
    "            batch_size, 1, trg_seq_len, trg_seq_len)\n",
    "        return trg_mask.to(self.device)\n",
    "\n",
    "    def forward(self, src, trg):\n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        enc_out = self.encoder(src, src_mask)\n",
    "        out = self.decoder(trg, enc_out, src_mask, trg_mask)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6617c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델의 단일 학습 단계\n",
    "def step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device):\n",
    "    enc_src = enc_src.to(device)\n",
    "    dec_src = dec_src.to(device)\n",
    "    trg = trg.to(device)\n",
    "\n",
    "    # 모델을 통해 순전파 계산을 수행합니다.\n",
    "    logits = model(enc_src, dec_src)\n",
    "\n",
    "    # SOS 토큰을 대상에서 제외하고 마지막 logit을 제거하여 대상과 일치시킵니다.\n",
    "    logits = logits[:, :-1, :].contiguous()\n",
    "    trg = trg[:, 1:].contiguous()\n",
    "\n",
    "    loss = loss_fn(logits.view(-1, logits.shape[-1]), trg.view(-1))\n",
    "\n",
    "    # 정확도 계산\n",
    "    non_pad_elements = (trg != VOCAB['<PAD>']).nonzero(as_tuple=True)\n",
    "    correct_predictions = (logits.argmax(dim=2) == trg).sum().item()\n",
    "    accuracy = correct_predictions / len(non_pad_elements[0])\n",
    "\n",
    "    return loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50bbba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하나의 에포크 동안의 학습 루프\n",
    "def train_step(model, iterator, optimizer, loss_fn, clip, VOCAB, device):\n",
    "    model.train()  # 모델을 학습 모드로 설정합니다.\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "        enc_src, dec_src, trg = batch\n",
    "\n",
    "        # 기울기를 초기화합니다.\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss, accuracy = step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device)\n",
    "\n",
    "        # 역방향 계산을 수행합니다.\n",
    "        loss.backward()\n",
    "\n",
    "        # 기울기 폭발을 방지하기 위해 기울기를 클리핑합니다.\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "\n",
    "        # 파라미터를 업데이트합니다.\n",
    "        optimizer.step()\n",
    "\n",
    "        # 손실과 정확도를 누적합니다.\n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += accuracy\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c29e9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 학습 루프\n",
    "def train(model, train_loader, optimizer, loss_fn, clip, epochs, VOCAB, device, val_loader=None):\n",
    "    \"\"\"\n",
    "    모델을 지정된 에포크 수 동안 학습하고 선택적으로 평가합니다.\n",
    "\n",
    "    Args:\n",
    "        model (nn.Module): 학습할 모델.\n",
    "        train_loader (DataLoader): 학습 데이터에 대한 DataLoader.\n",
    "        optimizer (Optimizer): 모델 가중치를 업데이트하는 옵티마이저.\n",
    "        loss_fn (function): 오류를 계산하는 손실 함수.\n",
    "        clip (float): 기울기의 최대 허용 값 (기울기 폭발 방지).\n",
    "        epochs (int): 모델을 학습할 총 에포크 수.\n",
    "        VOCAB (dict): 어휘 사전 정보가 포함된 사전.\n",
    "        device (torch.device): 모델을 학습할 디바이스 (CPU/GPU).\n",
    "        val_loader (DataLoader, optional): 검증 데이터에 대한 DataLoader. None이면 검증을 생략합니다.\n",
    "\n",
    "    Returns:\n",
    "        nn.Module: 학습된 모델.\n",
    "    \"\"\"\n",
    "    for epoch in range(epochs):\n",
    "        # 하나의 에포크 동안 학습을 수행합니다.\n",
    "        train_loss, train_acc = train_step(model, train_loader, optimizer, loss_fn, clip, VOCAB, device)\n",
    "\n",
    "        # 결과를 기록할 문자열을 준비합니다.\n",
    "        result = f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc * 100:.2f}%'\n",
    "\n",
    "        # 검증 로더가 제공된 경우 검증을 수행합니다.\n",
    "        if val_loader:\n",
    "            eval_loss, eval_acc = evaluate_step(model, val_loader, loss_fn, VOCAB, device)\n",
    "            result += f' || Eval Loss: {eval_loss:.3f} | Eval Acc: {eval_acc * 100:.2f}%'\n",
    "\n",
    "        # 현재 에포크의 결과를 로그에 기록합니다.\n",
    "        print(f'Epoch: {epoch + 1:02}')\n",
    "        print(result)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893b59ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평가 단계\n",
    "def evaluate_step(model, iterator, loss_fn, VOCAB, device):\n",
    "    model.eval()  # 모델을 평가 모드로 설정합니다.\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "\n",
    "    with torch.no_grad():  # 기울기 계산을 비활성화합니다.\n",
    "        for i, batch in enumerate(iterator):\n",
    "            enc_src, dec_src, trg = batch\n",
    "\n",
    "            loss, accuracy = step(model, enc_src, dec_src, trg, loss_fn, VOCAB, device)\n",
    "\n",
    "            # 손실과 정확도를 누적합니다.\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += accuracy\n",
    "\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59266acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 입력 준비 함수\n",
    "def prepare_model_input(question, VOCAB, max_length=50, device='cuda'):\n",
    "    # 입력 질문을 토큰화\n",
    "    tokenized_question = text_to_tokens(question)\n",
    "    enc_src = tokenized_question + [VOCAB['<EOS>']]  # EOS 토큰을 끝에 추가\n",
    "    # 인코더 소스 길이가 최대 길이를 초과하지 않도록 보장\n",
    "    if len(enc_src) > max_length:\n",
    "        enc_src = enc_src[:max_length]  # 시퀀스를 최대 길이로 자름\n",
    "    padded_enc_src = F.pad(torch.LongTensor(enc_src), (0, max_length - len(enc_src)), mode='constant',\n",
    "                           value=VOCAB['<PAD>']).unsqueeze(0).to(device)  # 패딩 및 디바이스로 이동\n",
    "    # 디코더 입력을 <SOS> 토큰으로 시작하는 자리 표시자를 준비\n",
    "    dec_src = torch.LongTensor([VOCAB['<SOS>']]).unsqueeze(0).to(device)\n",
    "\n",
    "    return padded_enc_src, dec_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a94af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 트랜스포머와 채팅하는 함수\n",
    "def chat_with_transformer(model, VOCAB, max_length=50, temperature=1.0, device='cpu'):\n",
    "    model.eval().to(device)\n",
    "\n",
    "    while True:  # 채팅 세션을 위한 무한 루프 시작\n",
    "        question = input(\"You: \")  # 사용자로부터 입력 받음\n",
    "        if question.lower() == \"bye\":  # 사용자가 대화를 끝내고 싶어하는지 확인\n",
    "            print(\"Bot: Goodbye!\")\n",
    "            break  # 사용자가 'bye'라고 하면 루프를 종료\n",
    "        # 모델 입력 준비\n",
    "        enc_src, dec_src = prepare_model_input(question, VOCAB=VOCAB, max_length=max_length, \n",
    "                                               device=device)\n",
    "\n",
    "        generated_answer = []\n",
    "        with torch.no_grad():\n",
    "            for _ in range(max_length):\n",
    "                logits = model(enc_src, dec_src)\n",
    "                # 마지막 토큰만 고려하도록 조정\n",
    "                predictions = F.softmax(logits[:, -1, :] / temperature, dim=1)  \n",
    "                predicted_token = torch.multinomial(predictions, num_samples=1).squeeze(1)\n",
    "#                 predicted_token = torch.argmax(predictions, dim=1)\n",
    "\n",
    "                if predicted_token.item() == VOCAB['<EOS>']:\n",
    "                    break  # EOS 토큰이 예측되면 토큰 생성을 중지\n",
    "                # 디코더 입력을 업데이트\n",
    "                dec_src = torch.cat([dec_src, predicted_token.unsqueeze(-1)], dim=1)  \n",
    "                generated_answer.append(predicted_token.item())\n",
    "\n",
    "                response = tokens_to_text(generated_answer, VOCAB)  # 토큰 ID를 텍스트로 변환\n",
    "        print(f\"Bot: {response}\")  # 봇의 응답을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b28cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 저장 함수\n",
    "def save_data(data, path=\"./dataset/data2.pkl\"):\n",
    "    with open(path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "    print(f\"Data saved to {path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85157860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 함수\n",
    "def load_data(path=\"./dataset/data2.pkl\"):\n",
    "    with open(path, \"rb\") as f:\n",
    "        data = pickle.load(f)\n",
    "    print(f\"Data loaded from {path}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1f8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 기본 전처리\n",
    "df = pd.read_csv('./dataset/dialogs.txt', sep='\\t', names=['Question', 'Answer'])\n",
    "df['QUESTION_CLEAN'] = df['Question'].apply(clean_text)\n",
    "df['ANSWER_CLEAN'] = df['Answer'].apply(clean_text)\n",
    "\n",
    "# 모든 문장을 토큰화\n",
    "tokenizer = get_tokenizer('basic_english')\n",
    "special_tokens = ['<SOS', '<EOS>', '<UNK>', '<PAD>']\n",
    "\n",
    "# 질문과 답변을 쌍으로 만듭니다.\n",
    "qa_pairs = list(zip(df['QUESTION_CLEAN'], df['ANSWER_CLEAN']))\n",
    "\n",
    "# 학습 및 검증 세트로 분리\n",
    "train_pairs, val_pairs = train_test_split(qa_pairs, test_size=0.01, random_state=42)\n",
    "\n",
    "# 편의를 위해 질문과 답변을 분리\n",
    "train_questions, train_answers = zip(*train_pairs)\n",
    "val_questions, val_answers = zip(*val_pairs)\n",
    "\n",
    "# 어휘 사전 구축\n",
    "train_texts = train_questions + train_answers + val_questions + val_answers\n",
    "VOCAB = build_vocab_from_iterator(yield_tokens(train_texts), \n",
    "                                  specials=['<PAD>', '<SOS>', '<EOS>', '<UNK>'])\n",
    "VOCAB.set_default_index(VOCAB['<UNK>'])\n",
    "\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "get_max_length = lambda train_texts: max(len(text.split()) for text in train_texts)\n",
    "INPUT_SEQ_LEN = TARGET_SEQ_LEN = get_max_length(train_texts)\n",
    "\n",
    "print('VOCAB_SIZE:', VOCAB_SIZE)\n",
    "print('INPUT_SEQ_LEN:', INPUT_SEQ_LEN)\n",
    "print('TARGET_SEQ_LEN:', TARGET_SEQ_LEN)\n",
    "save_data([VOCAB, TARGET_SEQ_LEN], path=\"./dataset/vocab_simple_transformer_v7_new2.pkl\")\n",
    "\n",
    "train_dataset = QADataset(train_pairs, VOCAB, tokenizer, INPUT_SEQ_LEN, TARGET_SEQ_LEN)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "transformer = TransformerScratch(\n",
    "    inp_vocab_size=VOCAB_SIZE,\n",
    "    trg_vocab_size=VOCAB_SIZE,\n",
    "    src_pad_idx=VOCAB['<PAD>'],\n",
    "    trg_pad_idx=VOCAB['<PAD>'],\n",
    "    emb_size=256,\n",
    "    n_layers=2,\n",
    "    heads=8,\n",
    "    forward_expansion=4,\n",
    "    drop_out=0.05,\n",
    "    max_seq_len=TARGET_SEQ_LEN,\n",
    "    device=device\n",
    ").to(device)\n",
    "\n",
    "loss_function = torch.nn.CrossEntropyLoss(ignore_index=VOCAB['<PAD>'], reduction='mean')\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.00001)\n",
    "\n",
    "transformer = train(transformer, train_dataloader, optimizer, loss_function, clip=1, \n",
    "                    epochs=10000, VOCAB=VOCAB, device=device)\n",
    "\n",
    "# 모델 저장\n",
    "torch.save(transformer.state_dict(), './models/simple_transformer_v7_new2.pth')\n",
    "\n",
    "chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc01c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')\n",
    "VOCAB, TARGET_SEQ_LEN = load_data(path=\"./models/simple_transformer_v7_new_final/vocab_simple_transformer_v7_new.pkl\")\n",
    "VOCAB_SIZE = len(VOCAB)\n",
    "transformer = TransformerScratch(\n",
    "    inp_vocab_size=VOCAB_SIZE,\n",
    "    trg_vocab_size=VOCAB_SIZE,\n",
    "    src_pad_idx=VOCAB['<PAD>'],\n",
    "    trg_pad_idx=VOCAB['<PAD>'],\n",
    "    emb_size=256,\n",
    "    n_layers=2,\n",
    "    heads=8,\n",
    "    forward_expansion=4,\n",
    "    drop_out=0.05,\n",
    "    max_seq_len=TARGET_SEQ_LEN,\n",
    "    device=device\n",
    ").to(device)\n",
    "transformer.load_state_dict(torch.load('./models/simple_transformer_v7_new_final/simple_transformer_v7_new.pth'))\n",
    "chat_with_transformer(transformer, VOCAB, max_length=TARGET_SEQ_LEN, temperature=1.5, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2856ebd1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fusion_env",
   "language": "python",
   "name": "fusion_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
