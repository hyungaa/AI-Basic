{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50269cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import re\n",
    "import pickle\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f52735",
   "metadata": {},
   "outputs": [],
   "source": [
    "#하이퍼 파라미터\n",
    "hidden_size = 256\n",
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "MAX_LENGTH = 10\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedf743a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if pd.isna(text):  # NaN값을 처리\n",
    "        return ''\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'\\d+', ' ', text)   #숫자를 공백으로\n",
    "    text = re.sub(r'([^\\w\\s])', r' \\1 ', text)   # 마침표 앞 뒤로 공백 추가\n",
    "    text = re.sub(r'\\s+', ' ', text)  # 두개 이상의 공백은 하나의 공백으로..\n",
    "    text = text.strip()  # 텍스트 앞 뒤의 공백 제거\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd6f3b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(vocab, sentence):\n",
    "    return [vocab.get(word, vocab['<UNK>']) for word in sentence.split(' ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df632606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensorFromSentence(vocab, sentence):\n",
    "    indexes = indexesFromSentence(vocab, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605b7e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output, hidden = self.lstm(embedded, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "320af9a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLSTM(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.lstm = nn.LSTM(hidden_size, hidden_size, num_layers=2)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.lstm(output, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return (torch.zeros(2, 1, self.hidden_size, device=device),\n",
    "                torch.zeros(2, 1, self.hidden_size, device=device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac0bab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    loss = 0\n",
    "    \n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    for di in range(target_length):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "        topv, topi = decoder_output.topk(1)\n",
    "        decoder_input = topi.squeeze().detach()\n",
    "        loss += criterion(decoder_output, target_tensor[di])\n",
    "        if decoder_input.item() == EOS_token:\n",
    "            break\n",
    "    \n",
    "    loss.backward()    # backpropagation only 1 line!\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ffa63af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습을 반복해주는 코드\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
    "    print_loss_total = 0\n",
    "    \n",
    "    for iter in range(1, n_iters+1):\n",
    "        training_pair = random.choice(pairs)\n",
    "        input_tensor = tensorFromSentence(word_to_ix, training_pair[0]).to(device)\n",
    "        target_tensor = tensorFromSentence(word_to_ix, training_pair[1]).to(device)\n",
    "        \n",
    "        loss = train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        \n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print(f'Iteration: {iter}, Loss: {print_loss_avg: .4f}')\n",
    "            print_loss_total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f007a36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(word_to_ix, sentence).to(device)\n",
    "        input_length = input_tensor.size(0)\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        encoder_hidden = tuple([e.to(device) for e in encoder_hidden])\n",
    "        \n",
    "        for ei in range(input_length):\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoded_words = []  # output sentence\n",
    "        \n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                 decoded_words.append(ix_to_word[topi.item()])   #여기는 최종 아웃풋의 인덱스가 들어갑니다\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "        return ' '.join(decoded_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2666a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 채팅함수\n",
    "def chat(encoder, decoder, max_length=MAX_LENGTH):\n",
    "    print(\"Let's chat! (type 'bye' to exit)\")\n",
    "    while True:\n",
    "        input_sentence = input(\"> \")\n",
    "        if input_sentence == 'bye':\n",
    "            break\n",
    "        output_sentence = evaluate(encoder, decoder, input_sentence)\n",
    "        print('<', output_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba101c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드 및 기본 전처리 부분을..\n",
    "df = pd.read_csv('./dataset/chatbot_dataset.txt', sep='\\t', names=['Question', 'Answer'])\n",
    "df['Encoder Inputs'] = df['Question'].apply(clean_text)\n",
    "df['Decoder Inputs'] = df['Answer'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "35a6ca40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                      i ' m fine . how about yourself ?\n",
       "1                i ' m pretty good . thanks for asking .\n",
       "2                    no problem . so how have you been ?\n",
       "3                   i ' ve been great . what about you ?\n",
       "4         i ' ve been good . i ' m in school right now .\n",
       "                             ...                        \n",
       "295        i first learned how to do it in high school .\n",
       "296    did you take some sort of art class or somethi...\n",
       "297                         that was my favorite class .\n",
       "298                        you have got to be talented .\n",
       "299                                             thanks .\n",
       "Name: Decoder Inputs, Length: 300, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Decoder Inputs']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcbaae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sentence = [sentence for sentence in df['Encoder Inputs']]\n",
    "output_sentence = [sentence + \"<EOS>\" for sentence in df['Decoder Inputs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "46849f63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hi , how are you doing ?',\n",
       " \"i ' m fine . how about yourself ?\",\n",
       " \"i ' m pretty good . thanks for asking .\",\n",
       " 'no problem . so how have you been ?',\n",
       " \"i ' ve been great . what about you ?\"]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sentence[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3151016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i ' m fine . how about yourself ?<EOS>\",\n",
       " \"i ' m pretty good . thanks for asking .<EOS>\",\n",
       " 'no problem . so how have you been ?<EOS>',\n",
       " \"i ' ve been great . what about you ?<EOS>\",\n",
       " \"i ' ve been good . i ' m in school right now .<EOS>\"]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentence[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c2f78445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 사전 생성\n",
    "all_words = set(' '.join(df['Encoder Inputs'].tolist()+df['Decoder Inputs'].tolist()).split())\n",
    "vocab = {'<PAD>': PAD_token, '<SOS>': SOS_token, '<EOS>': EOS_token, '<UNK>': UNK_token}\n",
    "vocab.update({word: i+4 for i, word in enumerate(all_words)})\n",
    "vocab_size = len(vocab)\n",
    "# vocab 변수 저장\n",
    "with open('./dataset/vocab.pkl', 'wb') as f:\n",
    "    pickle.dump(vocab, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b24d9c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_ix = vocab\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1596f924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "327"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_ix['hello']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "110f56e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'truth'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ix_to_word[167]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c261724",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = EncoderLSTM(vocab_size, hidden_size).to(device)\n",
    "decoder = DecoderLSTM(hidden_size, vocab_size).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "19af137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.005)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.005)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5f8baca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pairs 리스트를 만들어서 학습 데이터를 준비\n",
    "pairs = [list(x) for x in zip(df['Encoder Inputs'], df['Decoder Inputs'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dee1de5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"i ' m fine . how about yourself ?\",\n",
       " \"i ' m pretty good . thanks for asking .\"]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6193a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 1000, Loss:  3.1257\n",
      "Iteration: 2000, Loss:  2.9322\n",
      "Iteration: 3000, Loss:  2.7119\n",
      "Iteration: 4000, Loss:  2.3395\n",
      "Iteration: 5000, Loss:  2.0017\n",
      "Iteration: 6000, Loss:  1.6962\n",
      "Iteration: 7000, Loss:  1.4017\n",
      "Iteration: 8000, Loss:  1.2547\n",
      "Iteration: 9000, Loss:  1.0569\n",
      "Iteration: 10000, Loss:  0.8863\n",
      "Iteration: 11000, Loss:  0.7781\n",
      "Iteration: 12000, Loss:  0.6946\n",
      "Iteration: 13000, Loss:  0.7157\n",
      "Iteration: 14000, Loss:  0.5904\n",
      "Iteration: 15000, Loss:  0.5542\n",
      "Iteration: 16000, Loss:  0.4554\n",
      "Iteration: 17000, Loss:  0.5023\n",
      "Iteration: 18000, Loss:  0.4672\n",
      "Iteration: 19000, Loss:  0.5450\n",
      "Iteration: 20000, Loss:  0.4171\n",
      "Iteration: 21000, Loss:  0.4262\n",
      "Iteration: 22000, Loss:  0.4565\n",
      "Iteration: 23000, Loss:  0.4016\n",
      "Iteration: 24000, Loss:  0.3283\n",
      "Iteration: 25000, Loss:  0.4269\n",
      "Iteration: 26000, Loss:  0.5385\n",
      "Iteration: 27000, Loss:  0.4403\n",
      "Iteration: 28000, Loss:  0.2090\n",
      "Iteration: 29000, Loss:  0.1817\n",
      "Iteration: 30000, Loss:  0.3995\n"
     ]
    }
   ],
   "source": [
    "#학습실행 def trainIters(encoder, decoder, n_iters, print_every=1000, learning_rate=0.01):\n",
    "trainIters(encoder, decoder, 30000, print_every=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "65b8cd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(encoder.state_dict(), './models/encoder_tmp.pth')\n",
    "torch.save(decoder.state_dict(), './models/decoder_tmp.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "15c617a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecoderLSTM(\n",
       "  (embedding): Embedding(433, 256)\n",
       "  (lstm): LSTM(256, 256, num_layers=2)\n",
       "  (out): Linear(in_features=256, out_features=433, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가실행\n",
    "encoder.eval()\n",
    "decoder.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff9928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's chat! (type 'bye' to exit)\n",
      "> how are you?\n",
      "< how shoes have you nice how <EOS>\n",
      "> How's today?\n",
      "< how me how she bad . <EOS>\n",
      "> I think not ready yet\n",
      "< really really it you really hope really ? <EOS>\n",
      "> not a good chatbot\n",
      "< i think m you . <EOS>\n",
      "> don't think of me\n",
      "< is to you the weather going ? <EOS>\n"
     ]
    }
   ],
   "source": [
    "chat(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f8821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab 변수 로드\n",
    "with open('./dataset/vocab.pkl', 'rb') as f:\n",
    "    vocab = pickle.load(f)\n",
    "vocab_size = len(vocab)\n",
    "word_to_ix = vocab\n",
    "ix_to_word = {i: word for word, i in word_to_ix.items()}\n",
    "encoder = EncoderLSTM(vocab_size, hidden_size).to(device)\n",
    "decoder = DecoderLSTM(hidden_size, vocab_size).to(device)\n",
    "\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr=0.005)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr=0.005)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
